{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <PDF 요약 웹사이트 만들기>\n",
    "PyPDF2 : PDF 파일 읽고, 분할, 병합, 순서 바꾸고, 추가, 암호화 등의 작업 할 수 있게 해주는 라이브러리  \n",
    "        파이썬에서 PDF 파일을 처리하기 위한 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 15:21:34.270 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/envs/lchain/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import streamlit as st \n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import FAISS # 고성능 벡터 검색 라이브러리 / 텍스트 청크를 벡터화한 후 검색 수행하는데 사용됨\n",
    "from langchain.chains.question_answering import load_qa_chain # 질문-응답 체인을 로드하는 데 사용됨\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "def process_text(text):\n",
    "    # CharacterTextSplitter를 사용하여 텍스트를 청크로 분할\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator='\\n',             # 줄바꿈을 기준으로 텍스트 분할\n",
    "        chunk_size=1000,            # 각 청크의 최대 길이\n",
    "        chunk_overlap=200,          # 청크 간의 중복되는 부분의 길이\n",
    "        length_function=len         # 텍스트 길이 계산하는 함수\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text) # text를 입력 받아 설정한 대로 청크로 분할\n",
    "\n",
    "    # 임베딩 처리(벡터 변환), 임베딩은 HuggingFaceEmbeddings 모델을 사용\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    documents = FAISS.from_texts(chunks, embeddings) # 텍스트 청크를 벡터로 변환하고 FAISS db에 저장\n",
    "    return documents\n",
    "\n",
    "def main() : # streamlit을 이용한 웹사이트 생성\n",
    "    st.title('PDF 요약하기')\n",
    "    st.divider() # 페이지에 구분선 추가\n",
    "\n",
    "    pdf = st.file_uploader('PDF파일을 업로드해주세용', type='pdf') # 사용자가 PDF 파일을 업로드할 수 있는 위젯 제공\n",
    "\n",
    "    if pdf is not None:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        text = '' # 텍스트 변수에 PDF 내용을 저장\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "\n",
    "        documents = process_text(text) # PDF에서 추출한 텍스트를 청크로 분할하고, 벡터화한 후 FAISS db에 저장\n",
    "        query = '업로드된 PDF 파일의 내용을 약 3~5문장으로 요약해주세요' # LLM에 PDF파일 요약 요청\n",
    "\n",
    "        if query:\n",
    "            docs = documents.similarity_search(query) # 쿼리와 가장 유사한 텍스트 청크 찾음\n",
    "            llm = Ollama(model='llama3')\n",
    "            chain = load_qa_chain(llm, chain_type='stuff') # 질문-응답 체인 로드/ 유사 문서에서 정보 추출하여 질문에 대한 답변 생성하는 데 사용\n",
    "\n",
    "            # 질문과 유사 문서를 바탕으로 LLM이 답변 반환\n",
    "            response = chain.run(input_documents=docs, question=query)\n",
    "\n",
    "            st.subheader('--요약 결과--') # 요약 결과를 표시할 부분의 제목 설정\n",
    "            st.write(response) \n",
    "\n",
    "if __name__ == '__main__': # 스크립트가 직접 실행될 때 'main()'함수 호출 / import되어 사용될 때와 구분 \n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
